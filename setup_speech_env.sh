#!/bin/bash

# éŸ³å£°èªè­˜ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# AMD GPU (ROCm) å¯¾å¿œç‰ˆ

set -e

PROJECT_NAME="speech-to-text-project"
PYTHON_VERSION="python3"

echo "=== éŸ³å£°èªè­˜ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é–‹å§‹ ==="
echo "æ—¥æ™‚: $(date)"
echo "Python: $($PYTHON_VERSION --version)"
echo ""

# è‰²ä»˜ããƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”¨é–¢æ•°
print_success() {
    echo -e "\033[32mâœ“ $1\033[0m"
}

print_warning() {
    echo -e "\033[33mâš ï¸ $1\033[0m"
}

print_error() {
    echo -e "\033[31mâœ— $1\033[0m"
}

print_info() {
    echo -e "\033[34mâ„¹ï¸ $1\033[0m"
}

# 1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
echo "1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ"
if [ ! -d "$PROJECT_NAME" ]; then
    mkdir -p $PROJECT_NAME
    print_success "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: $PROJECT_NAME"
else
    print_info "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ—¢å­˜: $PROJECT_NAME"
fi

cd $PROJECT_NAME

# 2. ä»®æƒ³ç’°å¢ƒä½œæˆ
echo ""
echo "2. Pythonä»®æƒ³ç’°å¢ƒä½œæˆ"
if [ ! -d "venv" ]; then
    $PYTHON_VERSION -m venv venv
    print_success "ä»®æƒ³ç’°å¢ƒä½œæˆå®Œäº†"
else
    print_info "ä»®æƒ³ç’°å¢ƒæ—¢å­˜"
fi

# 3. ä»®æƒ³ç’°å¢ƒæœ‰åŠ¹åŒ–
echo ""
echo "3. ä»®æƒ³ç’°å¢ƒæœ‰åŠ¹åŒ–"
source venv/bin/activate
print_success "ä»®æƒ³ç’°å¢ƒæœ‰åŠ¹åŒ–: $(which python)"

# 4. pipã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰
echo ""
echo "4. pipã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰"
pip install --upgrade pip wheel setuptools
print_success "pipæ›´æ–°å®Œäº†"

# 5. ROCmç’°å¢ƒå¤‰æ•°è¨­å®š
echo ""
echo "5. ROCmç’°å¢ƒå¤‰æ•°è¨­å®š"
cat > .env << 'EOF'
# ROCmç’°å¢ƒå¤‰æ•°
export ROCM_PATH=/opt/rocm
export HIP_PATH=/opt/rocm
export HSA_PATH=/opt/rocm
export LD_LIBRARY_PATH=/opt/rocm/lib:$LD_LIBRARY_PATH
export PATH=/opt/rocm/bin:$PATH

# GPUè¨­å®š
export HSA_OVERRIDE_GFX_VERSION=11.5.1
export HIP_VISIBLE_DEVICES=0

# Ollamaè¨­å®š
export OLLAMA_GPU_RUNNER=rocm
export OLLAMA_MAX_VRAM=3GB
EOF

source .env
print_success "ç’°å¢ƒå¤‰æ•°è¨­å®šå®Œäº†"

# 6. PyTorch (ROCmç‰ˆ)ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
echo ""
echo "6. PyTorch (ROCmç‰ˆ) ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
print_info "ROCmå¯¾å¿œPyTorchã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­..."
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.6
print_success "PyTorch ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†"

# 7. éŸ³å£°é–¢é€£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
echo ""
echo "7. éŸ³å£°é–¢é€£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"

# OpenAI Whisper
print_info "OpenAI Whisperã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­..."
pip install openai-whisper
print_success "OpenAI Whisper ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†"

# éŸ³å£°å‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
print_info "éŸ³å£°å‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­..."
pip install librosa soundfile pydub
print_success "éŸ³å£°å‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†"

# Web APIç”¨
print_info "Web APIãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­..."
pip install flask flask-cors requests python-dotenv
print_success "Web APIãƒ©ã‚¤ãƒ–ãƒ©ãƒª ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†"

# é–‹ç™ºç”¨ãƒ„ãƒ¼ãƒ«
print_info "é–‹ç™ºç”¨ãƒ„ãƒ¼ãƒ«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­..."
pip install jupyter notebook ipython
print_success "é–‹ç™ºç”¨ãƒ„ãƒ¼ãƒ« ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†"

# 8. requirements.txtä½œæˆ
echo ""
echo "8. requirements.txtä½œæˆ"
pip freeze > requirements.txt
print_success "requirements.txtä½œæˆå®Œäº†"

# 9. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ä½œæˆ
echo ""
echo "9. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ä½œæˆ"
mkdir -p {src,tests,data/audio,notebooks,docs}

# ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
cat > src/__init__.py << 'EOF'
# Speech-to-Text Project
__version__ = "0.1.0"
EOF

cat > src/speech_processor.py << 'EOF'
"""
éŸ³å£°èªè­˜å‡¦ç†ã‚¯ãƒ©ã‚¹
"""
import whisper
import requests
import logging

class SpeechProcessor:
    def __init__(self, whisper_model="tiny", ollama_model="phi3:mini"):
        self.whisper_model = whisper.load_model(whisper_model)
        self.ollama_model = ollama_model
        self.ollama_url = "http://localhost:11434"
        
    def transcribe_audio(self, audio_path):
        """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›"""
        result = self.whisper_model.transcribe(audio_path)
        return result["text"]
    
    def process_with_llm(self, text, prompt_template=None):
        """LLMã§ãƒ†ã‚­ã‚¹ãƒˆå¾Œå‡¦ç†"""
        if prompt_template is None:
            prompt_template = "ä»¥ä¸‹ã®éŸ³å£°èªè­˜çµæœã‚’æ•´ç†ã—ã¦ãã ã•ã„: {text}"
        
        prompt = prompt_template.format(text=text)
        
        response = requests.post(
            f"{self.ollama_url}/api/generate",
            json={
                'model': self.ollama_model,
                'prompt': prompt,
                'stream': False
            },
            timeout=30
        )
        
        if response.status_code == 200:
            return response.json().get('response', '')
        else:
            raise Exception(f"LLMå‡¦ç†ã‚¨ãƒ©ãƒ¼: {response.status_code}")
    
    def full_pipeline(self, audio_path, use_llm=True):
        """å®Œå…¨ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†"""
        # éŸ³å£°èªè­˜
        transcribed_text = self.transcribe_audio(audio_path)
        
        if use_llm:
            # LLMå¾Œå‡¦ç†
            processed_text = self.process_with_llm(transcribed_text)
            return {
                'original': transcribed_text,
                'processed': processed_text
            }
        else:
            return {
                'original': transcribed_text,
                'processed': transcribed_text
            }
EOF

cat > src/api_server.py << 'EOF'
"""
Flask API ã‚µãƒ¼ãƒãƒ¼
"""
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
import os
import tempfile
from speech_processor import SpeechProcessor

app = Flask(__name__)
CORS(app)

# éŸ³å£°å‡¦ç†åˆæœŸåŒ–
processor = SpeechProcessor()

@app.route('/')
def index():
    return jsonify({
        'message': 'Speech-to-Text API Server',
        'version': '0.1.0',
        'endpoints': ['/health', '/transcribe']
    })

@app.route('/health')
def health():
    return jsonify({'status': 'healthy'})

@app.route('/transcribe', methods=['POST'])
def transcribe():
    try:
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
        if 'audio' not in request.files:
            return jsonify({'error': 'No audio file provided'}), 400
        
        audio_file = request.files['audio']
        use_llm = request.form.get('use_llm', 'true').lower() == 'true'
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
            audio_file.save(tmp_file.name)
            
            # éŸ³å£°å‡¦ç†å®Ÿè¡Œ
            result = processor.full_pipeline(tmp_file.name, use_llm=use_llm)
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            os.unlink(tmp_file.name)
            
        return jsonify(result)
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)
EOF

cat > tests/test_speech.py << 'EOF'
"""
éŸ³å£°èªè­˜ãƒ†ã‚¹ãƒˆ
"""
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from speech_processor import SpeechProcessor

def test_whisper_availability():
    """Whisperåˆ©ç”¨å¯èƒ½æ€§ãƒ†ã‚¹ãƒˆ"""
    try:
        import whisper
        models = whisper.available_models()
        print(f"âœ“ Whisperåˆ©ç”¨å¯èƒ½: {models}")
        return True
    except ImportError:
        print("âœ— Whisperæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")
        return False

def test_model_loading():
    """ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ"""
    try:
        processor = SpeechProcessor()
        print("âœ“ SpeechProcessoråˆæœŸåŒ–æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âœ— åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return False

if __name__ == "__main__":
    print("=== éŸ³å£°èªè­˜ãƒ†ã‚¹ãƒˆ ===")
    test_whisper_availability()
    test_model_loading()
EOF

cat > notebooks/speech_demo.ipynb << 'EOF'
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# éŸ³å£°èªè­˜ãƒ‡ãƒ¢\n",
    "OpenAI Whisper + Ollama LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from speech_processor import SpeechProcessor\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whisperãƒ¢ãƒ‡ãƒ«ç¢ºèª\n",
    "print(\"åˆ©ç”¨å¯èƒ½ãªWhisperãƒ¢ãƒ‡ãƒ«:\")\n",
    "print(whisper.available_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# éŸ³å£°å‡¦ç†åˆæœŸåŒ–\n",
    "processor = SpeechProcessor(whisper_model=\"tiny\")\n",
    "print(\"éŸ³å£°å‡¦ç†åˆæœŸåŒ–å®Œäº†\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
EOF

print_success "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ä½œæˆå®Œäº†"

# 10. GPUå‹•ä½œç¢ºèª
echo ""
echo "10. GPUå‹•ä½œç¢ºèª"
print_info "PyTorch GPUèªè­˜ç¢ºèªä¸­..."
python3 -c "
import torch
print(f'PyTorch version: {torch.__version__}')
print(f'CUDA available: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'GPU count: {torch.cuda.device_count()}')
    print(f'Current GPU: {torch.cuda.get_device_name()}')
else:
    print('GPUèªè­˜ãªã—ï¼ˆCPUãƒ¢ãƒ¼ãƒ‰ï¼‰')
"
print_success "GPUç¢ºèªå®Œäº†"

# 11. Whisperå‹•ä½œç¢ºèª
echo ""
echo "11. Whisperå‹•ä½œç¢ºèª"
print_info "Whisperãƒ¢ãƒ‡ãƒ«ç¢ºèªä¸­..."
python3 -c "
import whisper
models = whisper.available_models()
print(f'åˆ©ç”¨å¯èƒ½ãªWhisperãƒ¢ãƒ‡ãƒ«: {models}')

# è»½é‡ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
try:
    model = whisper.load_model('tiny')
    print('âœ“ Whisper tinyãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ')
except Exception as e:
    print(f'âœ— Whisperãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}')
"
print_success "Whisperç¢ºèªå®Œäº†"

# 12. ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†
echo ""
echo "=========================================="
echo "ğŸ‰ éŸ³å£°èªè­˜ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†ï¼"
echo "=========================================="
echo ""
echo "ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ :"
echo "$(pwd)"
tree -L 2 2>/dev/null || find . -type d -maxdepth 2 | sed 's/^/  /'
echo ""
echo "ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:"
echo "1. ä»®æƒ³ç’°å¢ƒæœ‰åŠ¹åŒ–: source venv/bin/activate"
echo "2. ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿: source .env"
echo "3. ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ: python tests/test_speech.py"
echo "4. APIã‚µãƒ¼ãƒãƒ¼èµ·å‹•: python src/api_server.py"
echo "5. Jupyterèµ·å‹•: jupyter notebook notebooks/"
echo ""
echo "ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªã‚³ãƒãƒ³ãƒ‰:"
echo "- ãƒ†ã‚¹ãƒˆ: python tests/test_speech.py"
echo "- API: python src/api_server.py"
echo "- ãƒ‡ãƒ¢: jupyter notebook"
echo ""
echo "âš™ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«:"
echo "- ä¾å­˜é–¢ä¿‚: requirements.txt"
echo "- ç’°å¢ƒå¤‰æ•°: .env"
echo "- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: src/"
echo ""
print_success "ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Œäº†ï¼"